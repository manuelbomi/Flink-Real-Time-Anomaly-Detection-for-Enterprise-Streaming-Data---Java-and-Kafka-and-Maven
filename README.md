# Flink Real-Time Anomaly Detection for Enterprise Streaming Data (Java + Kafka + Maven)

## Overview

Apache Flink is a high-performance, low-latency framework for real-time stream processing. It can ingest data from multiple sources including:


- Kafka, RabbitMQ, Kinesis – message queues

- Filesystems – HDFS, S3, local files

- Databases – JDBC, CDC (Change Data Capture)

- Socket streams – TCP/UDP

- Custom sources – sensors, IoT devices, or any real-time feed


This versatility is crucial in enterprise applications where data may originate from diverse systems.


Unlike Spark, Flink provides true stream-first processing (event-by-event) rather than micro-batching, which makes it ideal for low-latency real-time applications like anomaly detection.


This project demonstrates a real-time anomaly detection job that:

- Reads sensor data from a Kafka topic

- Computes sliding-window averages

- Flags anomalies where sensor readings deviate significantly from the window average
- 

The project is implemented in Java, packaged as a Maven JAR, and submitted to Flink. Running in Java provides:


- Lower latency and overhead than PyFlink

- Better integration with Flink’s checkpointing and fault tolerance

- Standardization for CI/CD and production deployments

---

## Project Directory Structure

```python
flink-anomaly/
├── pom.xml                                  # Maven build file with Flink dependencies
├── README.md                                # Project documentation
├── target/                                  # Generated by `mvn package`
│   ├── classes/                             # Compiled classes
│   └── flink-anomaly-1.0-SNAPSHOT.jar       # Executable JAR
├── src/
│   ├── main/
│   │   ├── java/
│   │   │   └── com/example/
│   │   │       └── AnomalyDetectionJob.java
│   │   └── resources/
│   │       └── application.properties       # Optional configs
│   └── test/
│       ├── java/
│       │   └── com/example/
│       │       └── AppTest.java             # Optional unit tests
│       └── resources/                        # Optional test configs
├── logs/                                    # Optional: store Flink job logs
└── scripts/
    └── run-flink-job.sh                      # Optional helper script


```

---

### Step 1: Install WSL and Ubuntu 22.04

Make sure your system has WSL2 and Ubuntu 22.04 installed:

```python
wsl --install -d Ubuntu-22.04
sudo apt update && sudo apt upgrade -y

```

Install Java 11 (required by Flink 1.19):

```python
sudo apt install openjdk-11-jdk -y
java -version

```

---

### Step 2: Install Flink and Kafka

#### Download Flink and extract:

```python
wget https://downloads.apache.org/flink/flink-1.19.1/flink-1.19.1-bin-scala_2.13.tgz
tar -xvzf flink-1.19.1-bin-scala_2.13.tgz
cd flink-1.19.1
```

#### Install Kafka (with Zookeeper) on WSL:

```python
wget https://downloads.apache.org/kafka/3.5.1/kafka_2.13-3.5.1.tgz
tar -xvzf kafka_2.13-3.5.1.tgz
cd kafka_2.13-3.5.1

```

#### Start Zookeeper:

```python
bin/zookeeper-server-start.sh config/zookeeper.properties
```

<img width="1280" height="720" alt="Image" src="https://github.com/user-attachments/assets/f2bc01a5-9f69-41c8-9ba4-399ed122ba3d" />


#### Start Kafka broker:

```python
bin/kafka-server-start.sh config/server.properties
```

#### Create a topic for sensor data:

```python
bin/kafka-topics.sh --create --topic sensor-data_2 --bootstrap-server localhost:9092
```

#### Start a Kafka producer to push test data:

```python
bin/kafka-console-producer.sh --topic sensor-data_2 --bootstrap-server localhost:9092
```

<img width="1280" height="720" alt="Image" src="https://github.com/user-attachments/assets/73d651dc-3453-4819-8ead-6ddb240af947" />

---

#### Start a Kafka Consumer

On another terminal, create Kafka consumer

bin/kafka-console-consumer.sh \
  --topic sensor-data_2 \
  --bootstrap-server localhost:9092 \
  --from-beginning

<img width="1280" height="720" alt="Image" src="https://github.com/user-attachments/assets/61b6fc7b-b6c1-46d3-accb-b87acbbabf93" />

## Step 3: Create a Maven Project

```python
sudo apt install maven -y
mvn archetype:generate \
  -DgroupId=com.example \
  -DartifactId=flink-anomaly \
  -DarchetypeArtifactId=maven-archetype-quickstart \
  -DinteractiveMode=false
cd flink-anomaly
```

<ins> Install Maven </ins>

<img width="1151" height="503" alt="Image" src="https://github.com/user-attachments/assets/c1adca8d-ac79-4e3e-92f3-62d6ac42d4a7" />

<img width="1253" height="420" alt="Image" src="https://github.com/user-attachments/assets/16dfa402-2151-4efd-80f2-c6586fc8ec71" />

<ins> Create Maven Project</ins>

<img width="1205" height="268" alt="Image" src="https://github.com/user-attachments/assets/9fb298a8-51df-4edc-aa2e-1d836b592a56" />



---

### Step 3a: Add Java Source

Place AnomalyDetectionJob.java inside:

```python
src/main/java/com/example/
```

Confirm:

```python
pwd
# ~/flink-anomaly/src/main/java/com/example
```
---

### Step 3b: Add Flink Dependencies

Edit pom.xml to include:

```python
<properties>
    <maven.compiler.source>11</maven.compiler.source>
    <maven.compiler.target>11</maven.compiler.target>
</properties>

<dependencies>
    <dependency>
        <groupId>org.apache.flink</groupId>
        <artifactId>flink-streaming-java</artifactId>
        <version>1.19.1</version>
    </dependency>
    <dependency>
        <groupId>org.apache.flink</groupId>
        <artifactId>flink-clients</artifactId>
        <version>1.19.1</version>
    </dependency>
    <dependency>
        <groupId>org.apache.flink</groupId>
        <artifactId>flink-connector-kafka</artifactId>
        <version>3.2.0-1.19</version>
    </dependency>
</dependencies>

```

---

### Step 4: Build the Project

```python
mvn clean package
```
<ins> mvn clean package </ins>

<img width="1280" height="720" alt="Image" src="https://github.com/user-attachments/assets/4987b1e5-a8c4-452d-9fba-6244c211b498" />

The JAR will appear in:

```python
target/flink-anomaly-1.0-SNAPSHOT.jar
```

---

### Step 5: Submit the Job to Flink

From your Flink directory:

```python
cp ~/flink-anomaly/target/flink-anomaly-1.0-SNAPSHOT.jar ~/flink-1.19.1/
cd ~/flink-1.19.1
./bin/flink run flink-anomaly-1.0-SNAPSHOT.jar

```

<ins> Job Running on Flink as obserced via Flink UI </ins>

<img width="1271" height="631" alt="Image" src="https://github.com/user-attachments/assets/2c8f2bb6-fdb5-4936-b5ec-43da45772858" />

---




#### Monitor anomalies in real time:

```python
tail -f log/flink-*-taskexecutor-0-*.out
```

<img width="1276" height="193" alt="Image" src="https://github.com/user-attachments/assets/766bbd50-c027-4fd1-a5a5-f9527c12d0c8" />

---

### Step 6: Why Use Java over PyFlink for Enterprise

- Lower runtime overhead, no Python harness

- Better checkpointing & state management

- Standard for CI/CD and production deployment pipelines

- Easier integration with Flink cluster resources (YARN, Kubernetes, REST)

Most enterprise Flink streaming jobs are Java/Scala JARs, often containerized.

> [!NOTE]
> PyFlink version of the project exist here: https://github.com/manuelbomi/Flink-for-Real-Time-Enterprise-Streaming-Data-Insights-and-Anomaly-Detection   and here: https://github.com/manuelbomi/Flink-and-Kafka-Based-Real-Time-Data-Engineering-Pipeline
>
> 



---

### Step 7: Enterprise Applications

This project can be extended for:

- Manufacturing: Detecting machine sensor anomalies to prevent downtime

- Banking: Real-time fraud detection from transaction streams

- Hospitality / Entertainment: Monitoring real-time bookings, occupancy, video streaming or equipment sensors for operational alerts
  
---

---

### Thank you for reading
---

### **AUTHOR'S BACKGROUND**
### Author's Name:  Emmanuel Oyekanlu
```
Skillset:   I have experience spanning several years in data science, developing scalable enterprise data pipelines,
enterprise solution architecture, architecting enterprise systems data and AI applications,
software and AI solution design and deployments, data engineering, high performance computing (GPU, CUDA), machine learning,
NLP, Agentic-AI and LLM applications as well as deploying scalable solutions (apps) on-prem and in the cloud.

I can be reached through: manuelbomi@yahoo.com

Website:  http://emmanueloyekanlu.com/
Publications:  https://scholar.google.com/citations?user=S-jTMfkAAAAJ&hl=en
LinkedIn:  https://www.linkedin.com/in/emmanuel-oyekanlu-6ba98616
Github:  https://github.com/manuelbomi

```
[![Icons](https://skillicons.dev/icons?i=aws,azure,gcp,scala,mongodb,redis,cassandra,kafka,anaconda,matlab,nodejs,django,py,c,anaconda,git,github,mysql,docker,kubernetes&theme=dark)](https://skillicons.dev)



  [![HitCount](https://hits.dwyl.com/manuelbomi/https://githubcom/manuelbomi/Flink-Real-Time-Anomaly-Detection-for-Enterprise-Streaming-Data---Java.svg?style=flat-square&show=unique)](http://hits.dwyl.com/manuelbomi/https://githubcom/manuelbomi/Flink-Real-Time-Anomaly-Detection-for-Enterprise-Streaming-Data---Java)

   https://hits.dwyl.com/manuelbomi/https://githubcom/manuelbomi/Flink-Real-Time-Anomaly-Detection-for-Enterprise-Streaming-Data---Java.json

